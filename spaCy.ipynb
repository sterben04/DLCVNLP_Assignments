{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZPKPysbm22p"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwsQwRvqnCyZ"
      },
      "source": [
        "**Question 1.** Create a python program to find it out the Named entity recognition(NER) from the following sentence using spacy and visualizing those parts in sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_S5hmBInFHR",
        "outputId": "332d6e3c-024b-4530-f6ff-fa078d1248e4"
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I saw a kitten eating chicken in the kitchen\")   # No named entities present!\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "displacy.serve(doc, style=\"ent\")\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbO5o1BUp0x5"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waWR8c2ZnMWO"
      },
      "source": [
        "**Question 2.** Find out the similar words from following list using spacy library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ6tXEXCnJtz",
        "outputId": "f4d3f48e-4237-4967-b8c5-aab015744290"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_md\")\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESMHMJlenQqa",
        "outputId": "688260ca-e808-4fad-dfa5-66119cfabe44"
      },
      "source": [
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\") \n",
        "tokens = nlp(\"ship car truck motor-bike jeep hagskdshd\")\n",
        "similar = {}\n",
        "for token1 in tokens:\n",
        "    for token2 in tokens:\n",
        "        print(token1.text, token2.text, token1.similarity(token2))\n",
        "        if(token1.similarity(token2) > 0.5):\n",
        "          if(token1 not in similar.keys()):\n",
        "            similar[token1]=[token2]\n",
        "          else:\n",
        "            similar[token1].append(token2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ship ship 1.0\n",
            "ship car 0.2815587\n",
            "ship truck 0.35367906\n",
            "ship motor 0.2741221\n",
            "ship - 0.030455196\n",
            "ship bike 0.19740233\n",
            "ship jeep 0.21036273\n",
            "ship hagskdshd 0.0\n",
            "car ship 0.2815587\n",
            "car car 1.0\n",
            "car truck 0.71134394\n",
            "car motor 0.5655214\n",
            "car - 0.1160374\n",
            "car bike 0.53577304\n",
            "car jeep 0.5652786\n",
            "car hagskdshd 0.0\n",
            "truck ship 0.35367906\n",
            "truck car 0.71134394\n",
            "truck truck 1.0\n",
            "truck motor 0.52424634\n",
            "truck - 0.059196077\n",
            "truck bike 0.48927912\n",
            "truck jeep 0.6284901\n",
            "truck hagskdshd 0.0\n",
            "motor ship 0.2741221\n",
            "motor car 0.5655214\n",
            "motor truck 0.52424634\n",
            "motor motor 1.0\n",
            "motor - 0.010074193\n",
            "motor bike 0.46072814\n",
            "motor jeep 0.40830103\n",
            "motor hagskdshd 0.0\n",
            "- ship 0.030455196\n",
            "- car 0.1160374\n",
            "- truck 0.059196077\n",
            "- motor 0.010074193\n",
            "- - 1.0\n",
            "- bike 0.0737416\n",
            "- jeep -0.01678796\n",
            "- hagskdshd 0.0\n",
            "bike ship 0.19740233\n",
            "bike car 0.53577304\n",
            "bike truck 0.48927912\n",
            "bike motor 0.46072814\n",
            "bike - 0.0737416\n",
            "bike bike 1.0\n",
            "bike jeep 0.42305312\n",
            "bike hagskdshd 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "jeep ship 0.21036273\n",
            "jeep car 0.5652786\n",
            "jeep truck 0.6284901\n",
            "jeep motor 0.40830103\n",
            "jeep - -0.01678796\n",
            "jeep bike 0.42305312\n",
            "jeep jeep 1.0\n",
            "jeep hagskdshd 0.0\n",
            "hagskdshd ship 0.0\n",
            "hagskdshd car 0.0\n",
            "hagskdshd truck 0.0\n",
            "hagskdshd motor 0.0\n",
            "hagskdshd - 0.0\n",
            "hagskdshd bike 0.0\n",
            "hagskdshd jeep 0.0\n",
            "hagskdshd hagskdshd 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCD-CBllsCWv",
        "outputId": "1864c8ea-15a1-4398-f648-42b350996931"
      },
      "source": [
        "similar"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ship: [ship],\n",
              " car: [car, truck, motor, bike, jeep],\n",
              " truck: [car, truck, motor, jeep],\n",
              " motor: [car, truck, motor],\n",
              " -: [-],\n",
              " bike: [car, bike],\n",
              " jeep: [car, truck, jeep],\n",
              " hagskdshd: [hagskdshd]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVi6ptNsn6NK"
      },
      "source": [
        "**Question 3.** Visualize sentences including parts of speech(pos) tagging and linguistic annotation in it by using spacy library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbdgSWgbn1h3",
        "outputId": "b3129f5c-a59b-4e6b-b49f-82aa7966d3b3"
      },
      "source": [
        "from spacy import displacy\n",
        "doc = nlp(\"ship car truck motor-bike jeep hagskdshd\")\n",
        "displacy.serve(doc, style=\"dep\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liBJ8vu3osEr"
      },
      "source": [
        "**Question 4.** What is Word vector? And, how could you convert words into vector?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yquVct3ltuX3"
      },
      "source": [
        "Word vectors are simply vectors of numbers that represent the meaning of a word.Word vectors represent words as multidimensional continuous floating point numbers where semantically similar words are mapped to proximate points in geometric space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_YHXPHOuQ4L"
      },
      "source": [
        "Diffrent ways to convert words to vector include:\n",
        "  * Count Vectorizer\n",
        "  * TF-IDF Vectorizer\n",
        "  * Word2Vec\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byLgeIGPvbFa"
      },
      "source": [
        "####**Count Vectorizer** :\n",
        "\n",
        "**Step 1:** Identify unique words in the complete text data.\n",
        "\n",
        "**Step 2:** For each sentence, we’ll create an array of zeros with the same length \n",
        "\n",
        "**Step 3:** Taking each sentence one at a time, we’ll read the first word, find it’s total occurrence in the sentence. Once we have the number of times it appears in that sentence, we’ll identify the position of the word in the list above and replace the same zero with this count at that position. This is repeated for all words and for all sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkvRMt5kwK5L"
      },
      "source": [
        "#### **TF-IDF Vectorizer** :\n",
        "\n",
        "While Count Vectorizer converts each sentence into its own vector, it does not consider the importance of a word across the complete list of sentences. For example, 'He' is in two sentences and it provides no useful information in differentiating between the two. Thus, it should have a lower weight in the overall vector of the sentence. This is where the TF-IDF Vectorizer comes into the picture.\n",
        "\n",
        "\n",
        "TF-IDF is a product of two parts:\n",
        "\n",
        "**TF (Term Frequency)** — It is defined as the number of times a word appears in the given sentence.\n",
        "\n",
        "**IDF (Inverse Document Frequency)** — It is defined as the log to the base e of number of the total documents divided by the documents in which the word appears.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rATeG3-sxAFE"
      },
      "source": [
        "**Step 1**: Identify unique words in the complete text data\n",
        "\n",
        "**Step 2**: For each sentence, we’ll create an array of zeros with the same length \n",
        "\n",
        "**Step 3**: For each word in each sentence, we’ll calculate the TF-IDF value and update the corresponding value in the vector of that sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiO-KCGDxRIH"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#### **Word2Vec** :\n",
        "\n",
        "These are a set of neural network models that have the aim to represent words in the vector space. These models are highly efficient and performant in understanding the context and relation between words. Similar words are placed close together in the vector space while dissimilar words are placed wide apart.\n",
        "\n",
        "It is so amazing to represent words that it is even able to identify key relationships such that:\n",
        "\n",
        "king - Man + Women = Queen\n",
        "\n",
        "It is able to decipher that what a Man is to a King, a Woman is to a Queen. The respective relationships could be identified through these models.\n",
        "\n",
        "\n",
        "There are two models in this class:\n",
        "\n",
        "  1.CBOW (Continuous Bag of Words): The neural network takes a look at the surrounding words (say 2 to the left and 2 to the right) and predicts the word that comes in between\n",
        "\n",
        "  2.Skip-grams: The neural network takes in a word and then tries to predict the surrounding words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZO0JxkwovJs"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhrT0Cdgov99"
      },
      "source": [
        "**Question 5.** Define Vocab, hashes and lexemes in your own word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zzxBWXWypoE"
      },
      "source": [
        "*Vocab* is a Vocabulary where spaCy stores the data.\n",
        "\n",
        "To improve efficiency and save memory spaCy converts all strings to *hashes*. These hashes are then stored in a lookup table called StringStore.\n",
        "\n",
        "\n",
        "Each entry in the vocabulary is called *Lexeme*. It contains the context-independent information about a word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFOvCKQeoxwc"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}